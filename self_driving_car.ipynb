{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "from sklearn import svm\n",
    "from hyperopt import hp, fmin, tpe\n",
    "import imutils\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image, ImageFile\n",
    "import os\n",
    "from tensorflow.keras.layers import Input, Dense, Conv2D, MaxPooling2D, Dropout\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Program Files\\Python39\\lib\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:111: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.framework.config import set_memory_growth\n",
    "tf.compat.v1.disable_v2_behavior()\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(output_img_sz, ar=False):\n",
    "    '''\n",
    "    Function to preprocess training images\n",
    "\n",
    "            Parameters:\n",
    "                    output_img_sz (int): The width of the output image\n",
    "                    ar (int): 1 for maintaining aspect ratio and 0 for square image\n",
    "            Returns:\n",
    "                    Normalised and resized images and labels\n",
    "     '''\n",
    "    train_labels = pd.read_csv(\n",
    "        'C:/Users/Thomas/OneDrive/Desktop/UON/mlis2/project/training_norm.csv')\n",
    "    train_labels.head()\n",
    "    train_labels = train_labels.to_numpy()\n",
    "    images = []\n",
    "    train_labels[train_labels[:, 1] > 1, 2] = 1\n",
    "\n",
    "    \n",
    "\n",
    "    for x in train_labels[:, 0]:\n",
    "        imag_arr = Image.open(\n",
    "            'C:/Users/Thomas/OneDrive/Desktop/UON/mlis2/project/training_data/' + str(int(x))+'.png').convert('RGB')\n",
    "        if ar == False:\n",
    "            imag_arr = np.array(imag_arr.resize(\n",
    "                (output_img_sz, output_img_sz)))/255\n",
    "        else:\n",
    "            \n",
    "            imag_arr = imutils.resize(\n",
    "                np.array(imag_arr), width=output_img_sz)/255\n",
    "\n",
    "        images.append(imag_arr)\n",
    "    images = np.array(images)  \n",
    "    \n",
    "    train_labels = train_labels[:, 1:]\n",
    "    return images, train_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def additional_data(output_img_sz, dir, ar=False):\n",
    "    '''\n",
    "    Function to preprocess self collected images\n",
    "\n",
    "            Parameters:\n",
    "                    output_img_sz (int): The width of the output image\n",
    "                    ar (int): 1 for maintaining aspect ratio and 0 for square image\n",
    "                    dir (str): Directory of self collected images\n",
    "            Returns:\n",
    "                    Normalised and resized images and labels\n",
    "    '''\n",
    "    labels = []\n",
    "    images = []\n",
    "    \n",
    "    for text in os.listdir(dir):\n",
    "        imag_arr = Image.open(dir+'/'+text).convert('RGB')\n",
    "        if ar == False:\n",
    "            imag_arr = np.array(imag_arr.resize(\n",
    "                (output_img_sz, output_img_sz)))/255\n",
    "        else:\n",
    "            imag_arr = imutils.resize(\n",
    "                np.array(imag_arr), width=output_img_sz)/255\n",
    "        images.append(imag_arr)\n",
    "        split = text.split('_')\n",
    "        label1 = split[1]\n",
    "        label2 = split[2].split('.')[0]\n",
    "        labels.append([label1, label2])\n",
    "    images = np.array(images)\n",
    "    labels = np.array(labels, dtype=float)  \n",
    "    print(images.shape)\n",
    "    labels[:, 0] = (labels[:, 0]-50)/80\n",
    "    labels[:, 1] = labels[:, 1]/35\n",
    "\n",
    "    return images, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle(images, train_labels):\n",
    "    '''\n",
    "    Function to shuffle images and labels\n",
    "\n",
    "            Parameters:\n",
    "                    images (array): The width of the output image\n",
    "                    train_labels (array): 1 for maintaining aspect ratio and 0 for square image\n",
    "            Returns:\n",
    "                    shuffled images and labels\n",
    "    '''\n",
    "    index = np.random.permutation(images.shape[0])\n",
    "    images = images[index, :, :, :]\n",
    "    train_labels = train_labels[index, :]\n",
    "    return images, train_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(train_split, images, train_labels):\n",
    "    '''\n",
    "    Function to split images into testing and training groups\n",
    "\n",
    "            Parameters:\n",
    "                    train_split (float): The training split\n",
    "                    images (array): The images\n",
    "                    train_labels (array): The image labels\n",
    "            Returns:\n",
    "                    training and testing images and labels\n",
    "    '''\n",
    "    idx = int(len(images)*train_split)\n",
    "    train = images[:idx, :, :, :]\n",
    "    val = images[idx:, :, :, :]\n",
    "    val_labels = train_labels[idx:, :]\n",
    "    train_labels = train_labels[:idx, :]\n",
    "    return train, train_labels, val, val_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_CNN():\n",
    "    '''\n",
    "    Function to create CNN\n",
    "            Returns:\n",
    "                    CNN\n",
    "    '''\n",
    "    model = tf.keras.models.Sequential([\n",
    "        Conv2D(filters=64, kernel_size=3, activation='relu'),\n",
    "        MaxPooling2D(),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        Conv2D(filters=32, kernel_size=3, activation='relu'),\n",
    "        MaxPooling2D(),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        Conv2D(filters=32, kernel_size=3, activation='relu'),\n",
    "        MaxPooling2D(),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        Dense(300, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        Dense(160, activation='relu'),\n",
    "        Dense(2)\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_adjustable_CNN(f1, f2, f3, k1, k2, k3):\n",
    "    '''\n",
    "    Function to create adjustable CNN\n",
    "\n",
    "            Parameters:\n",
    "                   f1-f3 (int): The number of filters in layers 1-3\n",
    "                    k1-k3 (int): The kernel size for layers 1-3\n",
    "            Returns:\n",
    "                    Custom CNN\n",
    "    '''\n",
    "    model = tf.keras.models.Sequential([\n",
    "        Conv2D(filters=f1, kernel_size=k1, activation='relu', padding='same'),\n",
    "        MaxPooling2D(),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        Conv2D(filters=f2, kernel_size=k2, activation='relu', padding='same'),\n",
    "        MaxPooling2D(),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        Conv2D(filters=f3, kernel_size=k3, activation='relu', padding='same'),\n",
    "        MaxPooling2D(),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        Dense(300, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        Dense(160, activation='relu'),\n",
    "        Dense(2)\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class customcb(tf.keras.callbacks.Callback):\n",
    "    '''\n",
    "    Class to save best model when running a model multiple times\n",
    "\n",
    "    '''\n",
    "\n",
    "    def __init__(self, best_loss, dir):\n",
    "        super(customcb, self).__init__()\n",
    "        self.best_loss = best_loss\n",
    "        self.dir = dir\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if logs['val_loss'] < self.best_loss:\n",
    "            self.best_loss = logs['val_loss']\n",
    "            self.model.save(self.dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparamer tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(args):\n",
    "    '''\n",
    "    Function to produce minimisation objective for hyperparameter tuning\n",
    "\n",
    "            Parameters:\n",
    "                    args (list): The value of ar, image size, f1-f3 and k1-k3\n",
    "            Returns:\n",
    "                    The minimum validation loss of a single CNN\n",
    "    '''\n",
    "\n",
    "    ar, img_sz, f1, f2, f3, k1, k2, k3 = args\n",
    "    ar, img_sz, f1, f2, f3, k1, k2, k3 = ar[1], int(\n",
    "        img_sz[1]), f1[1], f2[1], f3[1], k1[1], k2[1], k3[1]\n",
    "    \n",
    "    images, labels = preprocess_data(img_sz, ar)\n",
    "    model = create_adjustable_CNN(int(f1), int(\n",
    "        f2), int(f3), int(k1), int(k2), int(k3))\n",
    "    train, train_labels, val, val_labels = train_test_split(\n",
    "        0.8, images, labels)\n",
    "    history = model.fit(train, train_labels, validation_data=(\n",
    "        val, val_labels), batch_size=100, epochs=200, verbose=0)\n",
    "    tf.keras.backend.clear_session()\n",
    "    return np.min(history.history['val_loss'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "space = [('ar_choice', hp.choice('ar', [0, 1])), ('image_size', hp.quniform('img_sz', 30, 120, 1)), ('filters1', hp.quniform('f1', 30, 80, 1)), ('filters2', hp.quniform(\n",
    "    'f2', 30, 80, 1)), ('filters3', hp.quniform('f3', 30, 80, 1)), ('kernel1', hp.quniform('k1', 3, 7, 1)), ('kernel2', hp.quniform('k2', 3, 7, 1)), ('kernel3', hp.quniform('k3', 3, 7, 1))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best = fmin(objective, space, algo=tpe.suggest, max_evals=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ar': 0, 'f1': 66.0, 'f2': 80.0, 'f3': 63.0, 'img_sz': 120.0, 'k1': 3.0, 'k2': 7.0, 'k3': 6.0}\n"
     ]
    }
   ],
   "source": [
    "print(best)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Optimal Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_save_model(args, callback):\n",
    "    '''\n",
    "    Function to use optimal hyperparmeters and save model\n",
    "\n",
    "            Parameters:\n",
    "                    args (list): The value of ar, image size, f1-f3 and k1-k3\n",
    "            Returns:\n",
    "                    Normalised and resized images and labels\n",
    "    '''\n",
    "\n",
    "    ar, img_sz, f1, f2, f3, k1, k2, k3 = args\n",
    "    ar, img_sz, f1, f2, f3, k1, k2, k3 = ar[1], int(\n",
    "        img_sz[1]), f1[1], f2[1], f3[1], k1[1], k2[1], k3[1]\n",
    "    \n",
    "    images, labels = preprocess_data(img_sz, ar)\n",
    "    model = create_adjustable_CNN(int(f1), int(\n",
    "        f2), int(f3), int(k1), int(k2), int(k3))\n",
    "    train, train_labels, val, val_labels = train_test_split(\n",
    "        0.8, images, labels)\n",
    "    history = model.fit(train, train_labels, validation_data=(\n",
    "        val, val_labels), batch_size=100, epochs=300, verbose=0, callbacks=[callback])\n",
    "    tf.keras.backend.clear_session()\n",
    "    return np.min(history.history['val_loss'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#{'ar': 0, 'f1': 66.0, 'f2': 80.0, 'f3': 63.0, 'img_sz': 120.0, 'k1': 3.0, 'k2': 7.0, 'k3': 6.0}\n",
    "dir = 'C:/Users/Thomas/OneDrive/Desktop/UON/mlis2/project/Optimized_models/cnn.h5'\n",
    "losses = np.ones([1, 10])\n",
    "args = [('ar', 0), ('img_sz', 120.0), ('f1', 66.0), ('f2', 80.0),\n",
    "        ('f3', 63.0), ('k1', 3.0), ('k2', 7.0), ('k3', 6.0)]\n",
    "for i in range(10):\n",
    "    loss = objective_save_model(args, customcb(\n",
    "        best_loss=np.min(losses), dir=dir))\n",
    "    losses[0, i] = loss\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.008806848635865564 2.863938018865861e-07\n"
     ]
    }
   ],
   "source": [
    "cnn_mean_loss = np.mean(losses)\n",
    "cnn_var_loss = np.var(losses)\n",
    "print(cnn_mean_loss, cnn_var_loss)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_encoder(img_sz, train, val):\n",
    "    '''\n",
    "    Function to produce encoder model\n",
    "\n",
    "            Parameters:\n",
    "                    img_sz (list): The image size\n",
    "                    train (array): The train images\n",
    "                    val (array): The validation images\n",
    "            Returns:\n",
    "                    The encoder model\n",
    "    '''\n",
    "    tf.keras.backend.clear_session()\n",
    "    input = tf.keras.layers.Input(shape=[img_sz[0], img_sz[1], 3])\n",
    "    x = tf.keras.layers.Conv2D(40, 3, 2, activation='relu')(input)\n",
    "    x = tf.keras.layers.Conv2D(80, 3, 2, activation='relu')(x)\n",
    "    x = tf.keras.layers.Flatten()(x)\n",
    "    units = x.shape[1]\n",
    "    encoded = tf.keras.layers.Dense(100)(x)\n",
    "    x = tf.keras.layers.Dense(5200)(encoded)\n",
    "    x = tf.keras.layers.Reshape(target_shape=(20, 20, 13))(x)\n",
    "    x = tf.keras.layers.Conv2DTranspose(\n",
    "        80, 3, 2, padding='same', activation='relu')(x)\n",
    "    x = tf.keras.layers.Conv2DTranspose(\n",
    "        40, 3, 2, padding='same', activation='relu')(x)\n",
    "    decoded = tf.keras.layers.Conv2DTranspose(3, 3, 1, padding='same')(x)\n",
    "    auto_encoder = tf.keras.models.Model(inputs=[input], outputs=[decoded])\n",
    "    auto_encoder.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "    auto_encoder.fit(train, train, batch_size=120, epochs=50,\n",
    "                     validation_data=(val, val), verbose=0)\n",
    "    \n",
    "    encoder = tf.keras.models.Model(inputs=[input], outputs=[encoded])\n",
    "    encoder.save('encoder.h5')\n",
    "    return encoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = preprocess_data(80, 0)\n",
    "train, train_labels, val, val_labels = train_test_split(0.8, images, labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_encoder([80, 80], train, val)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SVM_loss(encoder, train, train_labels, val, val_labels, k1, C1, epsilon1, d1, k2, C2, epsilon2, d2):\n",
    "    '''\n",
    "    Function to fit SVM and return validation loss\n",
    "\n",
    "            Parameters:\n",
    "                    encoder (tf model): The encoder model\n",
    "                    train (array): The training data\n",
    "                    train_labels (array): The training labels\n",
    "                    val (array): The validation data\n",
    "                    val_labels (array): The validation labels\n",
    "                    k1,k2 (str): The SVM kernel\n",
    "                    C1,C2 (float): The SVM box constraint\n",
    "                    epsilon1,epsilon2 (float): The SVM epislon value\n",
    "                    d1,d2 (int): The polynomial kernel degree\n",
    "            Returns:\n",
    "                    The SVM validation loss\n",
    "    '''\n",
    "    encoded_train = np.zeros([len(train), 100])\n",
    "\n",
    "    dx = int(len(train)/10)\n",
    "    for x in range(10):\n",
    "        end_indx = np.min([dx*(x+1), len(train)])\n",
    "\n",
    "        encoded_train[dx*x:end_indx,\n",
    "                      :] = encoder.predict(train[dx*x:end_indx, :, :, :])\n",
    "\n",
    "    regress = svm.SVR(kernel=k1, C=C1, epsilon=epsilon1, degree=d1)\n",
    "    regress.fit(encoded_train, train_labels[:, 0])\n",
    "    classif = svm.SVR(kernel=k2, C=C2, epsilon=epsilon2, degree=d2)\n",
    "    classif.fit(encoded_train, train_labels[:, 1])\n",
    "\n",
    "    encoded_val = encoder.predict(val)\n",
    "    regress_preds = regress.predict(encoded_val)\n",
    "    classif_preds = classif.predict(encoded_val)\n",
    "    loss = (np.square(classif_preds-val_labels[:, 1]).mean())+(\n",
    "        np.square(regress_preds-val_labels[:, 0])).mean()\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(args):\n",
    "    '''\n",
    "     Objective to minimise for SVM hyperparameter tuning\n",
    "\n",
    "             Parameters:\n",
    "                     args (list): k1,k2,C1,C2,epsilon1,epsilon2,d1,d2\n",
    "             Returns:\n",
    "                     The SVM validation loss\n",
    "     '''\n",
    "    k1, k2, C1, C2, epsilon1, epsilon2, d1, d2 = args\n",
    "    \n",
    "    k1, C1, epsilon1, d1, k2, C2, epsilon2, d2 = k1[1], C1[1], epsilon1[1], int(\n",
    "        d1[1]), k2[1], C2[1], epsilon2[1], int(d2[1])\n",
    "    images, labels = preprocess_data(80, 0)\n",
    "    train, train_labels, val, val_labels = train_test_split(\n",
    "        0.8, images, labels)\n",
    "\n",
    "    encoder = tf.keras.models.load_model('encoder.h5')\n",
    "    return SVM_loss(encoder, train, train_labels, val, val_labels, k1, C1, epsilon1, d1, k2, C2, epsilon2, d2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "space = [('kernel1', hp.choice('k1', ['rbf', 'poly'])), ('kernel2', hp.choice('k2', ['rbf', 'poly'])), ('Con1', hp.quniform('C1', 1, 300, 1)), ('Con2', hp.uniform(\n",
    "    'C2', 1, 300)), ('epsilon1', hp.uniform('e1', 0.08, 1)), ('epsilon2', hp.uniform('e2', 0.08, 1)), ('d1', hp.quniform('d1', 2, 5, 1)), ('d2', hp.quniform('d2', 2, 5, 1))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best = fmin(objective, space, algo=tpe.suggest, max_evals=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C1': 38.0, 'C2': 87.71277285648118, 'd1': 2.0, 'd2': 3.0, 'e1': 0.08056123968432027, 'e2': 0.08033113935585406, 'k1': 0, 'k2': 0}\n"
     ]
    }
   ],
   "source": [
    "print(best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using best hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = preprocess_data(80, 0)\n",
    "train, train_labels, val, val_labels = train_test_split(0.8, images, labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "args = [('k1', 'rbf'), ('k2', 'rbf'), ('C1', 38.0), ('C2', 87.71277285648118),\n",
    "        ('e1', 0.08056123968432027), ('e2', 0.08033113935585406), ('d1', 2.0), ('d2', 3.0)]\n",
    "losses = []\n",
    "for i in range(10):\n",
    "    create_encoder([80, 80], train, val)\n",
    "    loss = objective(args)\n",
    "    losses.append(loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.040636647260010705\n",
      "4.665078189045113e-07\n"
     ]
    }
   ],
   "source": [
    "svm_mean_loss = np.mean(losses)\n",
    "svm_var_loss = np.var(losses)\n",
    "print(svm_mean_loss)\n",
    "print(svm_var_loss)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DT_loss(train, train_labels, val, val_labels, encoder, md1, md2, msl1, msl2):\n",
    "    '''\n",
    "    Function to produce decision tree loss\n",
    "\n",
    "            Parameters:\n",
    "                    encoder (tf model): The encoder model\n",
    "                    train (array): The training data\n",
    "                    train_labels (array): The training labels\n",
    "                    val (array): The validation data\n",
    "                    val_labels (array): The validation labels\n",
    "                    encoder (model): Encoder model\n",
    "                    md1,md2 (int): Max depth for each model\n",
    "                    msl1,msl2 (int): Minimum number of samples in leaf node for each model\n",
    "            Returns:\n",
    "                    The decision tree loss\n",
    "    '''\n",
    "    encoded_train = np.zeros([len(train), 100])\n",
    "    dx = int(len(train)/10)\n",
    "    for x in range(10):\n",
    "        end_indx = np.min([dx*(x+1), len(train)])\n",
    "\n",
    "        encoded_train[dx*x:end_indx,\n",
    "                      :] = encoder(train[dx*x:end_indx, :, :, :])\n",
    "    encoded_val = encoder(val)\n",
    "    clf1 = tree.DecisionTreeRegressor(max_depth=md1, min_samples_leaf=msl1)\n",
    "    clf2 = tree.DecisionTreeRegressor(max_depth=md2, min_samples_leaf=msl2)\n",
    "    clf1 = clf1.fit(encoded_train, train_labels[:, 0])\n",
    "    clf2 = clf2.fit(encoded_train, train_labels[:, 1])\n",
    "    predictions1 = clf1.predict(encoded_val)\n",
    "    predictions2 = clf2.predict(encoded_val)\n",
    "    loss1 = tf.keras.losses.MSE(predictions1, val_labels[:, 0])\n",
    "    loss2 = tf.keras.losses.MSE(predictions2, val_labels[:, 1])\n",
    "    return loss1+loss2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(args):\n",
    "     '''\n",
    "    Objective to minimise for DT hyperparameter tuning\n",
    "\n",
    "            Parameters:\n",
    "                    args (list): ar,img_sz,md1,md2,msl1,msl2\n",
    "            Returns:\n",
    "                    The DT validation loss\n",
    "    '''\n",
    "    ar,img_sz,md1,md2,msl1,msl2=args\n",
    "    img_sz,ar,md1,md2,msl1,msl2=int(img_sz[1]),ar[1],int(md1[1]),int(md2[1]),int(msl1[1]),int(msl2[1])\n",
    "    images,labels=preprocess_data(img_sz,ar)\n",
    "    train,train_labels,val,val_labels=train_test_split(0.8,images,labels)\n",
    "    encoder=create_encoder(images.shape[1:3],train,val)\n",
    "    return DT_loss(train,train_labels,val,val_labels,encoder,md1,md2,msl1,msl2)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "space = [('ar_choice', hp.choice('ar', [0, 1])), ('image_size', hp.quniform('img_sz', 30, 200, 1)), ('max_depth1', hp.quniform('md1', 30, 300, 1)),\n",
    "         ('max_depth2', hp.quniform('md2', 30, 300, 1)), ('min_samples1', hp.quniform('msl1', 1, 300, 1)), ('min_samples2', hp.quniform('msl2', 1, 300, 1))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best = fmin(objective, space, algo=tpe.suggest, max_evals=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DH_loss(encoder, train, train_labels, val, val_labels, d1, d2):\n",
    "     '''\n",
    "    Function to find loss of autoencoder with decision head model\n",
    "\n",
    "            Parameters:\n",
    "                    encoder (tf model): encoder model\n",
    "                    train (array): The training data\n",
    "                    train_labels (array): The training labels\n",
    "                    val (array): The validation data\n",
    "                    val_labels (array): The validation labels\n",
    "                    d1,d2 (int): Number of dense units in layers 1 and 2\n",
    "\n",
    "            Returns:\n",
    "                    The DH validation loss\n",
    "    '''\n",
    "    x=tf.keras.layers.Dense(d1,activation='relu',name='l')(encoder.output)\n",
    "    x=tf.keras.layers.Dropout(0.5)(x)\n",
    "    x=tf.keras.layers.Dense(d2,activation='relu',name='ll')(x)\n",
    "    x=tf.keras.layers.Dropout(0.5)(x)\n",
    "    output=tf.keras.layers.Dense(2,name='lll')(x)\n",
    "    encoder.trainable=False\n",
    "    final_model=tf.keras.models.Model(inputs=[encoder.input],outputs=[output])\n",
    "    final_model.compile(optimizer='adam',loss='mse')\n",
    "    history=final_model.fit(train,train_labels,validation_data=(val,val_labels),epochs=200,batch_size=120,verbose=0)\n",
    "    tf.keras.backend.clear_session()\n",
    "    return np.min(history.history['val_loss'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(args):\n",
    "    '''\n",
    "    Objective to minimise for DH hyperparameter tune\n",
    "\n",
    "            Parameters:\n",
    "                    args (list): d1 and d2\n",
    "\n",
    "            Returns:\n",
    "                    The DH validation loss\n",
    "    '''\n",
    "    tf.keras.backend.clear_session()\n",
    "    d1, d2 = args\n",
    "    d1, d2 = int(d1[1]), int(d2[1])\n",
    "    images, labels = preprocess_data(80, 0)\n",
    "    train, train_labels, val, val_labels = train_test_split(\n",
    "        0.8, images, labels)\n",
    "    encoder = tf.keras.models.load_model('encoder.h5')\n",
    "    return DH_loss(encoder, train, train_labels, val, val_labels, d1, d2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "space = [('dense1', hp.quniform('d1', 30, 500, 1)),\n",
    "         ('dense2', hp.quniform('d2', 5, 80, 1))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best = fmin(objective, space, algo=tpe.suggest, max_evals=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'d1': 431.0, 'd2': 76.0}\n"
     ]
    }
   ],
   "source": [
    "print(best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use best hyperparameterss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "args = [('d1', 431.0), ('d2', 76.0)]\n",
    "losses = []\n",
    "for i in range(10):\n",
    "    loss = objective(args)\n",
    "    losses.append(loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01641359026197799\n",
      "2.9602659501909622e-08\n"
     ]
    }
   ],
   "source": [
    "dh_mean_loss = np.mean(losses)\n",
    "dh_var_loss = np.var(losses)\n",
    "print(dh_mean_loss)\n",
    "print(dh_var_loss)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensemble(k, images, labels):\n",
    "    '''\n",
    "    Function to find loss of CNN ensemble\n",
    "\n",
    "            Parameters:\n",
    "                    k (int): Number of models\n",
    "                    images (array): The images\n",
    "                    labels (array): The labels\n",
    "\n",
    "            Returns:\n",
    "                    The mean ensemble validation loss\n",
    "    '''\n",
    "    losses = []\n",
    "\n",
    "    for i in range(k):\n",
    "        tf.keras.backend.clear_session()\n",
    "        top_index = (i+1)*int(np.ceil(len(images)/k))\n",
    "        bottom_index = i*int(np.ceil(len(images)/k))\n",
    "        val = images[bottom_index:top_index, :, :, :]\n",
    "        val_labels = labels[bottom_index:top_index, :]\n",
    "        train1 = images[:bottom_index, :, :, :]\n",
    "        train2 = images[top_index:, :, :, :]\n",
    "\n",
    "        train = np.concatenate([train1, train2], axis=0)\n",
    "        train_labels1 = labels[:bottom_index, :]\n",
    "        train_labels2 = labels[top_index:, :]\n",
    "        train_labels = np.concatenate([train_labels1, train_labels2], axis=0)\n",
    "        model = create_CNN()\n",
    "        history = model.fit(train, train_labels, validation_data=(\n",
    "            val, val_labels), batch_size=200, epochs=200, verbose=0)\n",
    "        losses.append(np.min(history.history['val_loss']))\n",
    "    return np.mean(np.array(losses))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(args):\n",
    "    '''\n",
    "    Objective for ensmeble for hyperparameter tuning\n",
    "            Parameters:\n",
    "                    args (list): ar,img_sz,\n",
    "\n",
    "            Returns:\n",
    "                    The mean ensemble validation loss\n",
    "    '''\n",
    "\n",
    "    ar, img_sz, k = args\n",
    "    ar = ar[1]\n",
    "    img_sz = int(img_sz[1])\n",
    "    k = int(k[1])\n",
    "    \n",
    "    images, labels = preprocess_data(img_sz, ar)\n",
    "    return ensemble(k, images, labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "space = [('ar_choice', hp.choice('ar', [0, 1])), ('image_size', hp.quniform(\n",
    "    'img_sz', 30, 120, 1)), ('number_mods', hp.quniform('k', 3, 15, 1))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best = fmin(objective, space, algo=tpe.suggest, max_evals=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ar': 0, 'img_sz': 70.0, 'k': 14.0}\n"
     ]
    }
   ],
   "source": [
    "print(best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using best hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensemble(k, images, labels, loss_hist):\n",
    "    '''\n",
    "    Function to find losses of ensemble and save best model given loss history\n",
    "\n",
    "            Parameters:\n",
    "                    k (int): Number of models\n",
    "                    images (array): The images\n",
    "                    labels (array): The labels\n",
    "                    loss_hist (array): The previous models best losses\n",
    "\n",
    "            Returns:\n",
    "                    The ensemble validation losses\n",
    "    '''\n",
    "    losses = []\n",
    "    dir = 'C:/Users/Thomas/OneDrive/Desktop/UON/mlis2/project/Optimized_models/ensemble_'\n",
    "    for i in range(k):\n",
    "        tf.keras.backend.clear_session()\n",
    "        top_index = (i+1)*int(np.ceil(len(images)/k))\n",
    "        bottom_index = i*int(np.ceil(len(images)/k))\n",
    "        val = images[bottom_index:top_index, :, :, :]\n",
    "        val_labels = labels[bottom_index:top_index, :]\n",
    "        train1 = images[:bottom_index, :, :, :]\n",
    "        train2 = images[top_index:, :, :, :]\n",
    "\n",
    "        train = np.concatenate([train1, train2], axis=0)\n",
    "        train_labels1 = labels[:bottom_index, :]\n",
    "        train_labels2 = labels[top_index:, :]\n",
    "        train_labels = np.concatenate([train_labels1, train_labels2], axis=0)\n",
    "        model = create_CNN()\n",
    "        best_loss = loss_hist[i]\n",
    "        history = model.fit(train, train_labels, validation_data=(val, val_labels), batch_size=200,\n",
    "                            epochs=200, verbose=0, callbacks=[customcb(best_loss=best_loss, dir=dir+str(i)+'.h5')])\n",
    "        losses.append(np.min(history.history['val_loss']))\n",
    "    return np.array(losses)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_save_model(args, loss_hist):\n",
    "    '''\n",
    "    Function to save best ensemble models given loss history\n",
    "\n",
    "            Parameters:\n",
    "                    args (list): ar,img_sz,k\n",
    "\n",
    "            Returns:\n",
    "                    The ensemble validation losses\n",
    "    '''\n",
    "    ar, img_sz, k = args\n",
    "    ar = ar[1]\n",
    "    img_sz = int(img_sz[1])\n",
    "    k = int(k[1])\n",
    "    \n",
    "    images, labels = preprocess_data(img_sz, ar)\n",
    "    return ensemble(k, images, labels, loss_hist)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = 'C:/Users/Thomas/OneDrive/Desktop/UON/mlis2/project/Optimized_models/ensemble'\n",
    "losses = np.ones([10, 14])\n",
    "args = [('ar', 0), ('img_sz', 70), ('k', 14)]\n",
    "\n",
    "for i in range(10):\n",
    "    loss = objective_save_model(args, np.min(losses, axis=0))\n",
    "    losses[i, :] = loss\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00821367 0.00812147 0.00787376 0.00811845 0.0082526  0.00854586\n",
      " 0.00830362 0.00792573 0.00800696 0.00800489]\n",
      "0.008136699618532871\n",
      "3.630559849796916e-08\n"
     ]
    }
   ],
   "source": [
    "means = np.mean(losses, axis=1)\n",
    "ensemble_mean_loss = np.mean(means, axis=0)\n",
    "ensemble_var_loss = np.var(means)\n",
    "print(means)\n",
    "print(ensemble_mean_loss)\n",
    "print(ensemble_var_loss)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.040636647260010705, 0.01641359026197799, 0.008806848635865564, 0.008136699618532871]\n",
      "(2, 4)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x27289a65430>"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhEAAAE/CAYAAAD40JHJAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAA1FElEQVR4nO3deZhU1Z3/8fdHWkRbFiWaMaJCghuCgCxqRAWNS9xwwQjBKGokbknml0lGnMwoMTrB6MRlNEaiRkUiKhoko0YjxD1R9tUQEdsIJjGgooKIDd/fH/d2W7TdXdW3u7qr4fN6nnq67r3nnHuqqqG+fVZFBGZmZmYNtVVLV8DMzMxaJwcRZmZmlomDCDMzM8vEQYSZmZll4iDCzMzMMnEQYWZmZpmUtXQFmsNWW20V2267bUtXw8zMrEHWrl0bEVGyf/BvEUHEtttuy5o1a1q6GmZmZg0i6aOWrkN9Sja6MTMzs9LmIMLMzMwycRBhZmZmmWwRYyLMWtInn3zC8uXLWbduXUtXxRqgXbt2dOnSha233rqlq2JWshxEmBXZ8uXLad++PV27dkVSS1fHChARrFq1iuXLl9OtW7eWro5ZyXJ3hlmRrVu3js6dOzuAaEUk0blzZ7cemeXhIMKsGTiAaH38mZnl5yDCbDM3ZMgQnnjiiU3O3XDDDVx44YV15hk8eDAzZ84E4LjjjuO99977TJqxY8dy3XXX1XvvKVOmsHjx4urjyy+/nKeeeqoBta/d008/zQknnNDocsyscTwmwqyZdR3zaJOWVzHu+HqvjxgxgkmTJnHMMcdUn5s0aRI//elPCyr/sccey1y3KVOmcMIJJ9CjRw8ArrzyysxlmVnpcUuE2WZu2LBhPProo6xfvx6AiooK3nrrLQ499FAuvPBC+vfvz3777ccVV1xRa/6uXbuycuVKAK6++mr22msvBg0axJIlS6rT/PKXv2TAgAH07t2b0047jbVr1/Liiy8ydepUfvCDH9CnTx9ee+01Ro0axeTJkwGYNm0affv2pVevXpx77rl8/PHH1fe74oorOOCAA+jVqxd//vOfC36t9913H7169aJnz55ceumlAGzYsIFRo0bRs2dPevXqxfXXXw/ATTfdRI8ePdh///0ZPnx4A99VMwMHEWabvR133JGBAwfy+OOPA0krxNe+9jUkcfXVVzNz5kzmz5/PM888w/z58+ssZ9asWUyaNIm5c+fy2GOPMWPGjOprp556KjNmzGDevHnsu+++3HHHHXz5y1/mpJNO4tprr2Xu3Ll86Utfqk6/bt06Ro0axf3338+CBQuorKzk1ltvrb7+uc99jtmzZ3PhhRfm7TKp8tZbb3HppZcyffp05s6dy4wZM5gyZQpz585lxYoVLFy4kAULFnDOOecAMG7cOObMmcP8+fP5xS9+0aD31MwSDiLMtgBVXRqQBBEjRowA4IEHHuCAAw6gb9++LFq0aJPxCzU999xznHLKKWy33XZ06NCBk046qfrawoULOfTQQ+nVqxcTJ05k0aJF9dZnyZIldOvWjb322guAs88+m2effbb6+qmnngpAv379qKioKOg1zpgxg8GDB7PTTjtRVlbGyJEjefbZZ/niF7/IsmXL+Pa3v83vfvc7OnToAMD+++/PyJEjuffeeykrc8+uWRYOIopo7NixSGqyx9ixY1v6JVkrNXToUKZNm8bs2bNZu3Yt/fr14/XXX+e6665j2rRpzJ8/n+OPPz7zlMZRo0Zx8803s2DBAq644opGT43cZpttAGjTpg2VlZWNKmuHHXZg3rx5DB48mF/84hd885vfBODRRx/l4osvZvbs2QwYMKDR97FmIJX+YwvjIKKIxo4dS0TU+zj88MM5/PDD86aLCAcRltn222/PkCFDOPfcc6tbId5//33Ky8vp2LEj//jHP6q7O+py2GGHMWXKFD766CM++OADfvvb31Zf++CDD9hll1345JNPmDhxYvX59u3b88EHH3ymrL333puKigqWLl0KwIQJEzj88MMb9RoHDhzIM888w8qVK9mwYQP33Xcfhx9+OCtXrmTjxo2cdtppXHXVVcyePZuNGzfy5ptvMmTIEK655hpWr17Nhx9+2Kj7m22J3IZntoUYMWIEp5xySnW3Ru/evenbty/77LMPu+22G4cccki9+Q844ADOOOMMevfuzc4778yAAQOqr/34xz/mwAMPZKedduLAAw+sDhyGDx/O+eefz0033VQ9oBKSJaV/9atfcfrpp1NZWcmAAQO44IILGvR6pk2bRpcuXaqPH3zwQcaNG8eQIUOICI4//niGDh3KvHnzOOecc9i4cSMAP/nJT9iwYQNnnnkmq1evJiL4zne+Q6dOnRp0fzMDRUTxCpeOBW4E2gC3R8S4Gte3Ae4B+gGrgDMioiLn+u7AYmBsRFxXSJm1KS8vjzVr1jTJa2rq6Xl///UYAP7l63lfRoPkm/ZnzeeVV15h3333belqWAb+7EpMa+guaOLvVElrI6K8SQttQkXrzpDUBrgF+CrQAxghqUeNZOcB70ZEd+B64Joa138GVLexFlimmZmZNYNijokYCCyNiGURsR6YBAytkWYocHf6fDJwpNK1ZiWdDLwO5A7zLqRMMzMzawbFHBOxK/BmzvFy4MC60kREpaTVQGdJ64BLgaOA7zewzJLx3vMTWf3CfQWlfeOa/Ev4djxkBJ0GjWxstczMzJpEqQ6sHAtcHxEfZt0ER9JoYDRA27Ztm65mDdBp0Eh/6ZuZ2WarmEHECmC3nOMu6bna0iyXVAZ0JBlgeSAwTNJPgU7AxrR1YlYBZQIQEeOB8ZAMrGzsizEzM7NNFTOImAHsKakbyRf9cODrNdJMBc4G/ggMA6ZHMl3k0KoEksYCH0bEzWmgka9MMzMzawZFG1gZEZXAJcATwCvAAxGxSNKVkqrWy72DZAzEUuB7wJgsZRbrNZhtLrbffvu8aZ577jn2228/+vTpw0cffdQMtWqYAw88kD59+rD77ruz00470adPH/r06cOLL77IsGHDWrp6Zlukoq4TUSpKeZ2IYvE6EaXjM2sNNPVc9wL+DW+//fZ5V2S84IILGDRoEGeeeWaBt01WUt1qq+Zd+Pauu+5i5syZ3HzzzUW/l9eJKDFeJ6LkeNlrsy3I008/zeDBgxk2bBj77LMPI0eOJCK4/fbbeeCBB/iv//ovRo5MBgNfe+21DBgwgP333796m/CKigr23ntvzjrrLHr27Mmbb75ZZ7p9992X888/n/3224+jjz66unVj6dKlfOUrX6F3794ccMABvPbaa3XerxAVFRX07NkTSAKMk08+maOOOoquXbty880387Of/Yy+ffty0EEH8c477wDw2muvceyxx9KvXz8OPfTQBm03bmafchBhtoWZM2cON9xwA4sXL2bZsmW88MILfPOb36zetnvixIk8+eSTvPrqq7z88svMnTuXWbNmVe+y+eqrr3LRRRexaNEilixZUm+6iy++mEWLFtGpUyceeughAEaOHMnFF1/MvHnzePHFF9lll13qvV9DLVy4kIcffpgZM2bwwx/+kO222445c+Zw8MEHc8899wAwevRo/vd//5dZs2Zx3XXXcdFFFzXBO2u25SnVKZ5mViQDBw6s3nOiT58+VFRUMGjQoE3SPPnkkzz55JP07dsXgA8//JBXX32V3XffnT322IODDjoob7pu3brRp08f4NMtvT/44ANWrFjBKaecAiR7aNRXzmGHHdbg1zdkyBDat29P+/bt6dixIyeeeCIAvXr1Yv78+Xz44Ye8+OKLnH766dV5Pv744wbfx8wcRJhtcaq22Ya6t9qOCC677DK+9a1vbXK+oqKC8vLygtLVvE99gzXrKieL3PtutdVW1cdbbbUVlZWVbNy4kU6dOjF37txG38tsS+fuDDP7jGOOOYY777yzejDmihUrePvttzOnq9K+fXu6dOnClClTgKQFYO3atQ0upzE6dOhAt27dePDBB4EkgJk3b15R7mW2uXNLhJl9xtFHH80rr7zCwQcfDCSzO+69917atGmTKV2uCRMm8K1vfYvLL7+crbfemgcffLDOcnbeeeeivL6JEydy4YUXctVVV/HJJ58wfPhwevfuXZR7mW3OPMWzgTzF0xrK0wRbL392JcZTPEuOuzPMzMwsEwcRZmZmlomDCDMzM8vEQYRZM9gSxh5tbvyZmeXnIMKsyNq1a8eqVav8pdSKRASrVq2qXgzLzGrnKZ5mRdalSxeWL1/OP//5z5auijVAu3btqlf2NLPaOYgwK7Ktt96abt26tXQ1zMyanLszzMzMLBMHEWZmZpaJgwgzMzPLxEGEmZlZKyXp/0laJGmhpPsktZPUTdJLkpZKul9S22Ld30GEmZlZKyRpV+A7QP+I6Am0AYYD1wDXR0R34F3gvGLVwUGEmZlZ61UGbCupDNgO+BtwBDA5vX43cHKxbu4gwszMrBWKiBXAdcBfSYKH1cAs4L2IqEyTLQd2LVYdHESYmZmVrjJJM3Meo6suSNoBGAp0A74AlAPHNmvlmvNmZmZm1iCVEdG/jmtfAV6PiH8CSHoYOAToJKksbY3oAqwoVuXcEmFmZtY6/RU4SNJ2kgQcCSwG/gAMS9OcDTxSrAo4iDAzM2uFIuIlkgGUs4EFJN/p44FLge9JWgp0Bu4oVh2K2p0h6VjgRpJpJ7dHxLga17cB7gH6AauAMyKiQtJAkjcCQMDYiPhNmqcC+ADYQP3NPGZmZpu1iLgCuKLG6WXAwOa4f9GCCEltgFuAo0hGh86QNDUiFuckOw94NyK6S6qa23oGsJBk3mulpF2AeZJ+mzPadEhErCxW3c3MzCy/YnZnDASWRsSyiFgPTCIZRZprKMkcVkiaZI6UpIhYmxMwtAOiiPU0MzOzDIoZROwKvJlzXNtc1eo0adCwmqT/BkkHSlpE0s9zQU5QEcCTkmblTnWpSdLoqikxlZWVdSUzMzOzjEp2imc6YGQ/SfsCd0t6PCLWAYMiYoWknYHfS/pzRDxbS/7xpOMqysvL3ZJhZmbWxIrZErEC2C3nuLa5qtVp0iU7O5IMsKwWEa8AHwI90+MV6c+3gd/QTINHzMzMbFPFDCJmAHumu4m1JdkUZGqNNFNJ5rBCMqd1ekREmqcMQNIewD5AhaRySe3T8+XA0SSDMM3MzKyZFa07I51ZcQnwBMkUzzsjYpGkK4GZETGVZO7qhHQu6zskgQbAIGCMpE+AjcBFEbFS0heB3yRralAG/Doifles12BmZmZ1U8TmP1ygvLw81qxZ0yRldR3zaJOUU2wV445v6SqYmTWt5A/I0tbE36mS1kZEeZMW2oS8YqWZmZll4iDCzMzMMnEQYWZmZpk4iDAzM7NMHESYmZlZJg4izMzMLBMHEWZmZpaJgwgzMzPLxEGEmZmZZeIgwszMzDJxEGFmZmaZOIgwMzOzTBxEmJmZWSYOIszMzCwTBxFmZmaWiYMIMzMzy8RBhJmZmWXiIMLMzMwycRBhZmZmmTiIMDMzs0wcRJiZmVkmDiLMzMwsEwcRZmZmlomDCDMzM8ukqEGEpGMlLZG0VNKYWq5vI+n+9PpLkrqm5wdKmps+5kk6pdAyzczMrHkULYiQ1Aa4Bfgq0AMYIalHjWTnAe9GRHfgeuCa9PxCoH9E9AGOBW6TVFZgmWZmZtYMitkSMRBYGhHLImI9MAkYWiPNUODu9Plk4EhJioi1EVGZnm8HRAPKNDMzs2ZQzCBiV+DNnOPl6bla06RBw2qgM4CkAyUtAhYAF6TXCynTzMzMmkHJDqyMiJciYj9gAHCZpHYNyS9ptKSZkmZWVlbmz2BmZmYNUswgYgWwW85xl/RcrWkklQEdgVW5CSLiFeBDoGeBZVblGx8R/SOif1lZWSNehpmZmdWmmEHEDGBPSd0ktQWGA1NrpJkKnJ0+HwZMj4hI85QBSNoD2AeoKLBMMzMzawZF+xM9IiolXQI8AbQB7oyIRZKuBGZGxFTgDmCCpKXAOyRBAcAgYIykT4CNwEURsRKgtjKL9RrMzMysboqI/KlaufLy8lizZk2TlNV1zKNNUk6xVYw7vqWrYGbWtKSWrkF+TfydKmltRJQ3aaFNKG9LhKQuJC0EhwJfAD4iWcfhUeDxiNhY1BqamZlZSao3iJD0K5IplP9HshDU2yTrNuxFsgjUDyWNiYhni11RMzMzKy35WiL+JyIW1nJ+IfBwOrhx96avlpmZmTUHSTsDh7Bpb8PMQnoa8gURf63nprtHxF+BpQ2oq5mZmZUASUOAMcCOwBw+7W04GfiSpMkkjQnv11VGviDiaeCA9GbTIuLInGtTqq6ZmZlZq3MccH7aILCJdJmFE4CjgIfqKiBfEJE7FHbHeq6ZmZlZKxIRP6jnWiVJY0G98i02FXU8r+3YzMzMWhlJ35XUQYk7JM2WdHQhefO1ROws6XskrQ5Vz0mPd2pEnc3MzKw0nBsRN0o6BtgB+AYwAXgyX8Z8QcQvgfa1PAe4PUNFzczMrLRUDU84DpiQri5d0JCFeoOIiPhRY2tmZmZmJW2WpCeBbiS7Zrcn2XIir3rHREg6X9Ke6XNJulPSaknzJfVtdLXNzMwsM0mdJE2W9GdJr0g6WNKOkn4v6dX05w55ijmPZKrngIhYC7QFzink/vkGVn6XZPdMgBFAb+CLwPeAmwq5gZmZmRXNjcDvImIfku/oV0gCgmkRsScwLT2uU7qoVCVwmKRTgcOB7oXcPN+YiMqI+CR9fgJwT0SsAp6S9NNCbmBmZmZNT1JH4DBgFEBErAfWSxoKDE6T3U2y5tOl9ZRzJ7A/sIhPuzECeDhfHfIFERsl7QK8CxwJXJ1zbdt8hZuZmVnRdAP+CfxKUm9gFkkPwucj4m9pmr8Dn89TzkER0SNLBfJ1Z1wOzCTp0pgaEYsAJB0OLMtyQzMzMytYmaSZOY/RuddIVo6+NSL6Amuo0XUREUH+dZ3+KClTEJFvdsb/SdoDaB8R7+ZcmgmckeWGZmZmVrDKiOhfx7XlwPKIeCk9nkwSRPxD0i4R8be0N+HtPPe4hySQ+DvwMcmUz4iI/fNVLt9W4KfmPK8tSd7+EjMzM2t6EfF3SW9K2jsilpAMO1icPs4GxqU/H8lT1B0kC0wtoMCpnVXyjYmYDMxNH7DpfhkFDbowMzOzovk2MFFSW5JhBueQDFV4QNJ5wBvA1/KU8c+ImJrl5vmCiFOB4SSjNh8B7osIb/1tZmZWAiJiLlBbd8eRtZyryxxJvwZ+S9KdUVV242ZnRMQUYIqkcmAo8D+SOgM/jIhnGlBBMzMzK03bkgQPuZtuNckUzyrrgNXA+8AeQLsGVtDMzMxKUEQUtDplbfIte32EpPEkc0+HADdGRJ+IeCLrDc3MzKzlSfpPSTvWc/0ISSfUV0a+loingPnA88A2wFmSzqq6GBHfaUB9zczMrHQsAH4raR0wm2ThqnbAnkAfkhjgv+srIF8QcS75F6kwMzOzViYiHgEeSTfaPATYhWTYwr3A6Ij4KF8Z+QZW3tWYCko6lmRzkDbA7RExrsb1bUgWuegHrALOiIgKSUeRzG9tC6wHfhAR09M8T5O80KoXd3RE5FtIw8zMzGoREa8Cr2bJm29MxC8l9azjWrmkcyWNrON6G+AW4KtAD2BELctqnge8GxHdgeuBa9LzK4ETI6IXyUIZE2rkG5mOzejjAMLMzKxl5OvOuAW4XFIvYCGb9pd0AO4EJtaRdyCwNCKWAUiaRDJNdHFOmqHA2PT5ZOBmSYqIOTlpFgHbStomIj7GzMzMSkK+7oy5wNckbU+ymEVVN8Ir6RKb9dkVeDPneDlwYF1pIqJS0mqgM0lLRJXTgNk1AohfSdoAPARclW4wYmZmZs2ooHUiIuJDkv3Im5Wk/Ui6OHIXwBgZESsktScJIr5BMq6iZt7RwGiAtm3bNkNtzczMWh9JewG3kmwh3lPS/sBJEXFVvrz5tgJvjBXAbjnHXdJztaaRVAZ0JBlgiaQuwG+AsyLitaoMEbEi/fkB8GuSbpPPiIjxEdE/IvqXlRW6ppaZmdkW55fAZcAnABExn2TLi7yKGUTMAPaU1C3dGGQ4UHODj6kkAycBhgHTIyIkdQIeBcZExAtViSWVSfpc+nxr4ASSsRpmZmaWzXYR8XKNc5WFZGxwECFpK0kd8qWLiErgEuAJ4BXggYhYJOlKSSelye4AOktaCnyPZB900nzdSQZ1zk0fO5MsePWEpPkkO4uuIImgzMzMLJuVkr5Eui6UpGHA3wrJqELGJKa7e10AbCBpYehAsgT2tVlr3JzKy8tjzZo1TVJW1zGPNkk5xVYx7viWroKZWdOSWroG+TXxOH9JayOivEkL/ew9vgiMB74MvAu8DpwZERX58hbaEtEjIt4HTgYeB7qRDGg0MzOzViwilkXEV4CdgH0iYlAhAQQUvovn1ukYhJOBmyPiE0meVmlmZtbKpeMQzwK6AmVKW3wK2R+r0CDiNqACmAc8K2kPkvW1zczMrHV7DPgTyYZcGxuSsdB1Im4Cbso59YakIQ25kZmZmZWkdhHxvSwZCxoTIem7kjoocYek2cARWW5oZmZmJWWCpPMl7SJpx6pHIRkLHVh5bjqw8mhgB5JBlePqz2JmZmatwHrgWuCPwKz0MbOQjIWOiaiaV3McMCFd76EVzLUxMzOzPP4N6B4RK/OmrKHQlohZkp4kCSKeSPetaNDgCzMzMytJS4G1WTIW2hJxHtAHWBYRayV1Bs7JckMzMzMrKWuAuZL+AFTvmN1kUzwjYmO6IdbX016MZyLitxkra2ZmZqVjSvposIKCCEnjgAHAxPTUdyQdHBH/keWmZmZmVhoi4u6seQvtzjgO6BMRGwEk3Q3MARxEmJmZtUKSHoiIr0laQLr5Vq6I2D9fGYUGEQCdgHfS5x0bkM/MzMxKz/XpzxOyFlBoEPETYE466ELAYXy6bbeZmZm1PrcAB0TEG1kLKHRg5X2SniYZFwFwKbBH1puamZlZi2v0ek8Fd2dExN+AqdV3ll4Gdm9sBczMzKxF7CrpprouNuUunrXxipVmZmat10ckS1xn1pgg4jMjOc3MzKzVWNWY6Z2QJ4iQ9FtqDxYEdG7Mjc3MzKxFrW9sAflaIq7LeM3MzMxKWEQc1Ngy6g0iIuKZxt7AzMzMNk+F7uJpZmZmtgkHEWZmZls4SYMknZM+30lSt0LyOYgwMzPbgkm6gmQRycvSU1sD9xaSt9BdPPcCfkCySmV1nog4okE1NTMzs1JzCtAXmA0QEW9Jal9IxkJbIh5MC/9PkmCi6lEvScdKWiJpqaTP7LUhaRtJ96fXX5LUNT1/lKRZkhakP4/IydMvPb9U0k2SvOiVmZlZdusjIkiXdJBUXmjGQhebqoyIWxtSI0ltSDb3OApYDsyQNDUiFuckOw94NyK6SxoOXAOcAawETkyjoZ7AE8CuaZ5bgfOBl4DHgGOBxxtSNzMzM6v2gKTbgE6SzgfOBX5ZSMZCWyJ+K+kiSbtI2rHqkSfPQGBpRCyLiPXAJGBojTRDgarVsiYDR0pSRMyJiLfS84uAbdNWi12ADhHxpzRqugc4ucDXYGZmZjVExHUk38EPAXsDl0fE/xaSt9CWiLPTn7ldGAF8sZ48uwJv5hwvBw6sK01EVEpaTbIS5sqcNKcBsyPiY0m7puXklrkrtZA0GhgN0LZt23qqaWZmtuVKZ2I8FxG/T4+3ldQ1Iiry5S10K/CCpno0NUn7kXRxHN3QvBExHhgPUF5e7n0+zMzMavcg8OWc4w3puQH5MhY6O2Nr4ELgsPTU08BtEfFJPdlWALvlHHdJz9WWZrmkMqAjsCq9ZxfgN8BZEfFaTvoueco0MzOzwpWlww4AiIj1kgpqwi90TMStQD/g5+mjX3quPjOAPSV1SyszHJhaI81UPu0qGQZMj4iQ1Al4FBgTES9UJY6IvwHvSzoonZVxFvBIga/BzMzMPuufkk6qOpA0lE2HFdSp0DERAyKid87xdEnz6suQjnG4hGRmRRvgzohYJOlKYGZETAXuACZIWgq8QxJoAFwCdAcul3R5eu7oiHgbuAi4C9iWZFaGZ2aYmZlldwEwUdLNJLt0v0nyR3peSiY55EkkzQZOr+pWkPRFYHJEHJC5ys2ovLw81qxZ0yRldR3zaJOUU2wV445v6SqYmTWt1rAsUAHfqQ0haW1EFLxuQyPvtT1ARHxYaJ5CWyJ+APxB0jKSKGUP4JwG19DMzMxKiqRtSGZCdgXKqtZwjIgr8+UtdHbGNEl7kswfBVgSER9nqq2ZmZmVkkeA1cAsoEHf7fUGEZKOiIjpkk6tcam7JCLi4YbV08zMzEpMl4g4NkvGfC0RhwPTgRNruRaAgwgzM7PW7UVJvSJiQUMz1htERMQV6dMrI+L13GuF7jVuZmZmxZPuVTUTWBERJ6Tfz5NIVoCeBXwjdx2IWgwCRkl6naQ7Q0BExP757l3oOhEP1XJucoF5zczMrHi+C7ySc3wNcH1EdAfeJdnssj5fBfYkWR36ROAEau+B+Ix6gwhJ+0g6Dego6dScxyigXSE3MDMzs+JIV3c+Hrg9PRZwBJ/+oX83eTaqjIg3SFaPPiJ9vpYCGxnyjYnYmyQi6cSmUckHJNtxm5mZWfGUSZqZczw+3Ruqyg3AvwPt0+POwHsRUZke17lRZRVJVwD9Sb7zfwVsDdwLHJK3cvVdjIhHgEckHRwRf8xXmJmZmTWpyojoX9sFSScAb0fELEmDG3GPU4C+wGyAiHhLUvv6syQKXWxqjqSLgf3I6caIiHMbWFEzMzNrGocAJ0k6juS7uQNwI9BJUlnaGlHIRpXr032rAkBSwStkFjqwcgLwL8AxwDNppT4o9CZmZmbWtCLisojoEhFdSfaemh4RI4E/kGxqCckml/k2qnxA0m0kwcf5wFPALwupQ6EtEd0j4nRJQyPibkm/Bp4rMK+ZmZk1n0uBSZKuAuaQbHZZq3Qg5v3APsD7JOMiLo+I3xdyo0KDiE/Sn+9J6gn8Hdi5wLxmZmZWRBHxNPB0+nwZMLDAfCHpsYjoBRQUOOQqtDtjvKQdgP8CpgKLgZ829GZmZmZWcmZLGpAlY6EbcN2ePn0G+GKWG5mZmVlJOhA4U1IFsIYGrFiZbwOu79V3PSJ+1oBKmpmZWek5JmvGfN0Z7dNHf+BCkgUrdgUuAA7IelMzMzMrDUVbsTIifgQg6VnggIj4ID0eCzzaiDqbmZlZCSjaipU5Pg/k7gC2Pj1nVlK6jikstn3v+YmsfuG+Jrtvx0NG0GnQyILSVow7vsnua2bWBIq+YuU9wMuSfpMenwzc1bA6mpmZWQnKvGJlobMzrpb0OHBoeuqciJjT8HqalYZOg0YW3HJgZraZq7li5bk0xYqVkjpExPuSdgQq0kfVtR0j4p3MVTYzM7MWI2mbiPg4Iq6TdBRFWLHy1yRbgc8CIvfe6bHXjDAzM2ud/ggcIGlCRHyDDCtW5pudcUL6s1u2+pmZmVmJaivp68CXJZ1a82JEPJyvgHzdGfWuBRERs/PkP5ZkW9I2wO0RMa7G9W1IBm32A1YBZ0REhaTOwGRgAHBXRFySk+dpYBfgo/TU0RHxdn31MDMzs8+4ABgJdAJOrHEtgMYFEcD/1HMtgCPquiipDXALcBSwHJghaWpELM5Jdh7wbkR0lzQcuAY4A1hHsk9Hz/RR08iImJmn7mZmZlaHiHgeeF7SzIioc6fP+uTrzhiSqWaJgcDSdDcxJE0ChpJs3lVlKDA2fT4ZuFmSImINyQvr3oj7m5mZWR4RcYekLwNdyYkLIuKefHkLXSeCdAvwHkC7Am+wK/BmzvFykk0+ak0TEZWSVgOdgZV5qvMrSRuAh4CrIiLypDczM7NaSJoAfAmYC2xITwfJcIN6FRREpEtiDiYJIh4Dvgo8X8gNimBkRKxIV9N6CPhGbfWQNBoYDdC2bdvmraGZmVnr0R/okeUP8oI22ACGAUcCf4+Ic4DeQMc8eVaQbOhRpUt6rtY0ksrSMlfVV2hErEh/fkAyBXVgHenGR0T/iOhfVlZwg4uZmdmWZiHwL1kyFvrt+lFEbJRUKakD8DabBgi1mQHsKakbSbAwHPh6jTRTgbNJ5qoOA6bXFwmlgUaniFgpaWuSNSyeKvA1mJmZ2Wd9Dlgs6WXg46qTEXFSvoyFBhEzJXUiWQZzFvAhyRd/ndIxDpcAT5BM8bwzIhZJuhKYGRFTgTuACZKWAu+QBBoASKoAOpDMYz0ZOBp4A3giDSDakAQQBS3NaWZmZrUamzVjvnUibgF+HREXpad+Iel3QIeImJ+v8Ih4jGQMRe65y3OerwNOryNv1zqK7ZfvvmZmZlaYiHgma958LRF/Aa6TtAvwAHCfN94yMzNr/SR9wKZbWlRfAiIiOuQrI986ETcCN0rag6Sr4U5J2wL3kQQUf2l4tc3MzKylRUT7xpZR0OyMiHgjIq6JiL7ACOBk4JXG3tzMzMxar4KCCEllkk6UNBF4HFgCfGazDjMzM9ty5BtYeRRJy8NxwMvAJGB0uiy1mZmZbcHyDay8jGRBp3+LiHeboT5mZmbWSuQbWFnnLp1mZma2ZSt02WszMzOzTTiIMDMzs0wcRJiZmVkmDiLMzMwsEwcRZmZmlomDCDMzM8vEQYSZmZll4iDCzMzMMnEQYWZmZpk4iDAzM7NMHESYmZlZJg4izMzMLBMHEWZmZpaJgwgzMzPLxEGEmZmZZeIgwszMzDJxEGFmZmaZOIgwMzOzTIoaREg6VtISSUsljanl+jaS7k+vvySpa3q+s6Q/SPpQ0s018vSTtCDNc5MkFfM1mJmZWe2KFkRIagPcAnwV6AGMkNSjRrLzgHcjojtwPXBNen4d8F/A92sp+lbgfGDP9HFs09fezMzM8ilmS8RAYGlELIuI9cAkYGiNNEOBu9Pnk4EjJSki1kTE8yTBRDVJuwAdIuJPERHAPcDJRXwNZmZmVodiBhG7Am/mHC9Pz9WaJiIqgdVA5zxlLs9TJgCSRkuaKWlmZWVlA6tuZmZm+Wy2AysjYnxE9I+I/mVlZS1dHTMzs81OMYOIFcBuOcdd0nO1ppFUBnQEVuUps0ueMs3MzKwZFDOImAHsKambpLbAcGBqjTRTgbPT58OA6elYh1pFxN+A9yUdlM7KOAt4pOmrbmZmVtok7ZbOZFwsaZGk76bnd5T0e0mvpj93KFYdihZEpGMcLgGeAF4BHoiIRZKulHRSmuwOoLOkpcD3gOppoJIqgJ8BoyQtz5nZcRFwO7AUeA14vFivwczMrIRVAv8WET2Ag4CL0+/KMcC0iNgTmEbOd2tTK+pggYh4DHisxrnLc56vA06vI2/XOs7PBHo2XS3NzMxan7R1/m/p8w8kvUIy2WAoMDhNdjfwNHBpMeqw2Q6sNLPWa+zYsUhqssfYsWNb+iWZFVW6WGNf4CXg82mAAfB34PPFuq+nLWyuWsNCnnUPf7Et3NixY/N+8Q8ePBiAp59+uuj1MWtBZZJm5hyPj4jxuQkkbQ88BPxrRLyfu5BzRISkov1n6yDCzJpF1zGPNml5f1+2qsnLrRh3fJOVZdZEKiOif10XJW1NEkBMjIiH09P/kLRLRPwtXaTx7WJVzt0ZZmZmrVA6S/EO4JWI+FnOpdyZj2dTxFmMbokwMzNrnQ4BvgEskDQ3PfcfwDjgAUnnAW8AXytWBRxEmFnJee/5iax+4b6C0r5xzQl503Q8ZASdBo1sbLXMSkq6x1RdA+CObI46OIgws5LTadBIf+mXqLFjx/KjH/2oycq74oorPHumFXMQYWa2hWvI4NT3nv9Lk977hqf+wl3rCrt/RZPe2ZqCgwgzMyuYW4ksl2dnmJmZWSYOIszMzCwTBxFmZmaWiYMIMzMzy8RBhJmZmWXiIMLMzMwycRBhZmZmmXidCLPm5m3azWwz4ZYIMzMzy8RBhJmZmWXiIMLMzMwycRBhZmZmmTiIMDMzs0wcRJiZmVkmDiLMzMwsk6IGEZKOlbRE0lJJY2q5vo2k+9PrL0nqmnPtsvT8EknH5JyvkLRA0lxJM4tZfzMzM6tb0RabktQGuAU4ClgOzJA0NSIW5yQ7D3g3IrpLGg5cA5whqQcwHNgP+ALwlKS9ImJDmm9IRKwsVt3NzMwsv2K2RAwElkbEsohYD0wChtZIMxS4O30+GThSktLzkyLi44h4HVialmdmZmYlophBxK7AmznHy9NztaaJiEpgNdA5T94AnpQ0S9Loum4uabSkmZJmVlZWNuqFmJmZ2We1xr0zBkXECkk7A7+X9OeIeLZmoogYD4wHKC8v90YAZmZmTayYLRErgN1yjruk52pNI6kM6Aisqi9vRFT9fBv4De7mMDMzaxHFDCJmAHtK6iapLclAyak10kwFzk6fDwOmR0Sk54ensze6AXsCL0sql9QeQFI5cDSwsIivwczMzOpQtO6MiKiUdAnwBNAGuDMiFkm6EpgZEVOBO4AJkpYC75AEGqTpHgAWA5XAxRGxQdLngd8kYy8pA34dEb8r1mswMzOzuhV1TEREPAY8VuPc5TnP1wGn15H3auDqGueWAb2bvqZmZmbWUF6x0szMzDJpjbMzzMyKI+kqLX3hCWdWGtwSYWZmZpk4iDAzM7NMHESYmZlZJg4izMzMLBMHEWZmZpaJgwgzMzPLxEGEmZmZZeIgwszMzDJxEGFmZmaZOIgwMzOzTBxEmJmZWSYOIszMzCwTBxFmZmaWiYMIMzMzy8RBhJmZmWXiIMLMzMwycRBhZmZmmTiIMDMzs0wcRJiZmVkmDiLMzMwsEwcRZmZmlomDCDMzM8ukqEGEpGMlLZG0VNKYWq5vI+n+9PpLkrrmXLssPb9E0jGFlmlmZralaOnvxKIFEZLaALcAXwV6ACMk9aiR7Dzg3YjoDlwPXJPm7QEMB/YDjgV+LqlNgWWamZlt9krhO7GYLREDgaURsSwi1gOTgKE10gwF7k6fTwaOlKT0/KSI+DgiXgeWpuUVUqaZmdmWoMW/E4sZROwKvJlzvDw9V2uaiKgEVgOd68lbSJlmZmZbghb/Tixrzps1J0mjgdHpYUj6qCXr09yUfLaVLV2PekktXYMW4c+mdLWKzwb8+ZSypv9stpU0M+d4fESMb+qbZFXMIGIFsFvOcZf0XG1plksqAzoCq/LkzVcmAOmbXDJvdHOTNDMi+rd0Peyz/NmULn82pc2fz2cU8j1bVMXszpgB7Cmpm6S2JAMlp9ZIMxU4O30+DJgeEZGeH57O3ugG7Am8XGCZZmZmW4IW/04sWktERFRKugR4AmgD3BkRiyRdCcyMiKnAHcAESUuBd0jeANJ0DwCLSZquLo6IDQC1lVms12BmZlaq6vqebc46KPnD3zY3kkaXUr+ZfcqfTenyZ1Pa/PmUHgcRZmZmlomXvTYzM7NMHESUIEknSwpJ++Sc6yrpI0lzcx5n1ZL3BElzJM2TtFjStyQdLumPNdKVSfqHpC9IukvSWkntc67fkNbhc8V9tU2nke/b0+nSsfMl/VnSzZI6ZazHSfUtPyupv6SbspRdS1kVuZ+RpMGS/q+Jyr5L0rCmKKuR9fihpEXpZzNX0oHp+duzrs6X/l4sbGCef5E0SdJrkmZJekzSXmlZIenbOWlvljQqfX6XpBWStkmPPyepIku9m5ukDTX+7TT7ssqSxkr6fi3n/RmWgM12nYhWbgTwfPrzipzzr0VEn7oySdqaZFrrwIhYnv7CdwVeBbpI2iMi3kiTfwVYFBFvKZnXvJRkpbN7JW0FHEEzTxVqApnetxwjI2JmOsr5J8AjwOENrUQ6aLjOEdIRMROYWdd1+5Skg4ETgAMi4uM0YGoLEBHfbMZ6CPgNcHdEDE/P9QY+T7LYz9vAdyXdlq4cWNMG4Fzg1maqclP5qMB/OyVvC/4Mi8otESVG0vbAIJJ9RYY3MHt7ksBwFUC6bPiSiNgIPFCjvOHAfTnHk4Az0ueDgRco9UVdcjTyfdtE+h/IvwO7p//JIOlMSS+nf43dpmTN+qrNb2anLT/T0nOjJN2cPj9d0sL0+rPpuerWAkk7SpqS/pX9J0n7p+fHSrozbSFZJuk7Gd6T8rSMl5W0Tg1Nz3eV9Fxa79mSvpyeV/rX1xJJTwE7N+Z9bCK7ACsj4mOAiFgZEW9BdetR//T5h5KuTt/nP0n6fHr+S+nxAklXSfqw5g2U7MtzraQZ6efwrVrqMQT4JCJ+UXUiIuZFxHPp4T+BaXw6Zb2mG4D/p2Q9nFZPSQvYj9LfnwVKW/+UtHpWtVrMUdq6KekHOe/vj9JzXZW0+t0l6S+SJkr6iqQXJL0qaWDOLXtL+mN6/vxa6uPPsIU4iCg9Q4HfRcRfgFWS+uVc+5I2bVo8NDdjRLxD8hfwG5LukzQybVWAJGCoir63AY4DHsrJ/hdgJ0k7kPwlP6kor654Mr9vtUmnFM8D9pG0L0mAdUj6V9kGYKSknYBfAqdFRG/g9FqKuhw4Jr1+Ui3XfwTMiYj9gf8A7sm5tg9wDMn6+FcoaWmqzR+qXhtwe875H5KsvTKQ5D/QayWVk/zFdVREHJC+rqqulVOAvUk28jkL+HId92tOTwK7pV8yP5dUV8tQOfCn9H1+Fqj6orkRuDEiepEsCVyb84DVETEAGACcr2R9mlw9gVl56noN8P2qALOGv5K0kn0jTxmlZtsa/3bOyLm2Mv0duhWo6m74PsmU/D7AocBHko4mWetnINAH6CfpsDR9d+B/SH7X9wG+TvLHwPdJ/j1U2Z+kdfRg4HJJX6hRT3+GLcQRVekZQfIfHyRf5CP49Bc/b7N8RHxTUi+S7orvA0cBo9Jm+u0l7Q3sC7yUBh25HiYJNA4EaovkS1mj3rc6VK1feyTQD5ihpOtnW5Iv4oOAZ9NN4qjl/YSkRecuJeuePFzL9UHAaWn+6ZI6S+qQXns0/Qv8Y0lvkzS71vZFOCQiVkLSysGn/6EfDZykT/uT2wG7A28BN0vqQxIQ7ZVePwy4Lw2g3pI0vY73pdlExIdpQHgoSSB0v6QxEXFXjaTrgaqxILNIfu8h+dI5OX3+a+C6Wm5zNLC/Ph3/0ZHkS+/1BtZ1maSXSL4Ia1PVRfZoQ8ptYfV1Z1T9Ps8CTk2fvwD8TNJE4OG0W/Vokvd4Tppme5L396/A6xGxAEDSImBaRISkBSRdsVUeiYiPSIKSP5AEJHNzrvszbCEOIkqIpB1Jou1ekoJk8ZCQ9IOGlJP+o1wgaQLJP6JR6aWq1oh92bQro8r9JP8h3B0RG9VK1udvqvetRpltgF7AKyTN+ndHxGU10pyYr5yIuEDJQMDjgVk1Wkjy+Tjn+QYa/u9VJK0kSzY5KY0F/gH0JmmNXNfAcptVGtQ8DTydfrmcDdxVI9kn8el89Ya+VwK+HRFP1JNmEcmquvn8N8mOxM/UvBARr6atRV9rQN1KWdXvZ/X7HRHjJD1K0tL5gqRjSN7fn0TEbbmZJXVl09/xjTnHG9n0M6y5FkHNY3+GLcTdGaVlGDAhIvaIiK4RsRtJEJC3+R2ScQHpX6JV+gBv5BzfB5xJ8oX7SM386aDLHwI/z1L5FtSo962mtNvgJ8CbETGfpJ90mKSd0+s7StoD+BNwWFWzaRrM1CzrSxHxUkRcTtLnuluNJM8BI9O0g0maiN/PUu9aPAF8W2k0KKlver4j8Ld0rMw3SIIuSLoBzkj7l3ch+cu/RUnaW9KeOaf6sOnvdD5/Im3poe6xMk8AF1Z1FykZrV9eI810YBslG/tV1W3/WroU/0yy0m5dAebVfNpStNlJf98XRMQ1JEsy70Py/p6rZNwSknat+rfUAEMltZPUmWTM1owa1/0ZthAHEaVlBMno4VwPpefhs337NQfbCfh3JQPj5pL0t4+quhgRrwBrSPrJ19RWgYi4LSJea/xLaVaNfd+qTJQ0H1hI0sc+FCAiFgP/CTyZXv89sEtE/JNkp9iHJc0jacmp6VolA88WAi+SjLPINZakj3g+MI66B3Vl8WNga2B+2lT84/T8z4Gz0zrvQ/I7Acl7+CrJf6D3AH+k5W0P3K1kuvJ8kvEaYxuQ/1+B76V5uwOra0lzO8lrnp1+TrdRoyUjbeU4BfiKkumBi0gCzb/XUt7VJBshfUa6JPHsBtS/pdUcEzEuT/p/VTKQeD7wCfB4RDxJ0pX0x7QlaTLJIPCGmA/8gSQo/HHV4Noc/gxbiFesNLPNlqTtSPr1Q9JwYEREDG3pepltLjwmwsw2Z/1IBpEKeI9knr+ZNRG3RJiZmVkmHhNhZmZmmTiIMDMzs0wcRJiZmVkmDiLMzMwsEwcRZmZmlomDCDMzM8vk/wMiHEK9eOI0XQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import t\n",
    "fig = plt.figure()\n",
    "ax = fig.add_axes([0, 0, 1, 1])\n",
    "models = ['AE SVM', 'AE Decision Head', 'Single CNN', 'Ensemble CNN']\n",
    "scores = [svm_mean_loss, dh_mean_loss, cnn_mean_loss, ensemble_mean_loss]\n",
    "print(scores)\n",
    "vars = [svm_var_loss, dh_var_loss, cnn_var_loss, ensemble_var_loss]\n",
    "lower_bounds = []\n",
    "upper_bounds = []\n",
    "talpha = t.ppf(0.025, 9)\n",
    "for i in range(4):\n",
    "    se = (vars[i]/10)**0.5\n",
    "    lower_bounds.append(talpha*se)\n",
    "    upper_bounds.append(-talpha*se)\n",
    "yerr = np.array([lower_bounds, upper_bounds])\n",
    "print(yerr.shape)\n",
    "xloc = np.arange(len(models))\n",
    "a = ax.bar(xloc-0.2, scores, yerr=np.abs(yerr),\n",
    "           width=0.4, capsize=10, label='Validation loss')\n",
    "\n",
    "plt.ylabel('Validation Loss (MSE)')\n",
    "plt.xticks(xloc, models)\n",
    "ax2 = ax.twinx()\n",
    "ax2.set_ylabel('Inference Time (ms)')\n",
    "b = ax2.bar(xloc+0.2, [20, 15, 9, 91], width=0.4,\n",
    "            capsize=10, color='red', label='Inference Time')\n",
    "ax.legend((a, b), ('Validation Loss', 'Inference Time'), loc='upper center')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x272898ecc40>"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_axes([0, 0, 1, 1])\n",
    "models = ['AE Decision Head', 'Single CNN', 'Ensemble CNN']\n",
    "scores = [dh_mean_loss, cnn_mean_loss, ensemble_mean_loss]\n",
    "vars = [dh_var_loss, cnn_var_loss, ensemble_var_loss]\n",
    "lower_bounds = []\n",
    "upper_bounds = []\n",
    "talpha = t.ppf(0.025, 9)\n",
    "for i in range(3):\n",
    "    se = (vars[i]/10)**0.5\n",
    "    lower_bounds.append(talpha*se)\n",
    "    upper_bounds.append(-talpha*se)\n",
    "yerr = np.array([lower_bounds, upper_bounds])\n",
    "print(yerr[:, 0].shape)\n",
    "xloc = np.arange(len(models))\n",
    "a = ax.bar(xloc-0.2, scores, yerr=np.abs(yerr),\n",
    "           width=0.4, capsize=10, label='Validation loss')\n",
    "\n",
    "plt.ylabel('Validation Loss (MSE)')\n",
    "plt.xticks(xloc, models)\n",
    "ax2 = ax.twinx()\n",
    "ax2.set_ylabel('Inference Time (ms)')\n",
    "b = ax2.bar(xloc+0.2, [15, 9, 91], width=0.4, capsize=10,\n",
    "            color='red', label='Inference Time',)\n",
    "ax.legend((a, b), ('Validation Loss', 'Inference Time'), loc='upper center')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# T-test for ensemble vs single CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00153087748357561\n"
     ]
    }
   ],
   "source": [
    "n = 10\n",
    "sp2 = ((n-1)*vars[-2]+(n-1)*vars[-1])/(2*n-2)\n",
    "tval = (scores[-2]-scores[-1])/((sp2*(1/n+1/n))**(1/2))\n",
    "pval = 2*(1-t.cdf(np.abs(tval), 2*n-2))\n",
    "print(pval)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ac59ebe37160ed0dfa835113d9b8498d9f09ceb179beaac4002f036b9467c963"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
